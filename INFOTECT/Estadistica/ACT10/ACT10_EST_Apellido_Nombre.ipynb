{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estadística\n",
    "## Entrega U5. 5C. Regresión lineal\n",
    "#### José Antonio García Casanova\n",
    "\n",
    "#### 3.7 Exercises\n",
    "\n",
    "#### Conceptual\n",
    "\n",
    "1. Describe the null hypotheses to which the p-values given in Table 3.4 correspond. Explain what conclusions you can draw based on these p-values. Your explanation should be phrased in terms of sales, TV, radio, and newspaper, rather than in terms of the coefficients of the linear model.\n",
    "\n",
    "\n",
    "![img1](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordemos que esta tabla habla de las ventas de productos utilizando a la televisión, el radio y periodicos como medios publicitarios.\n",
    "\n",
    "El p-value señala si nuestros coeficientes son significativos o no, esto es:\n",
    "\n",
    "$H^{0}_0 : \\beta_0 = 0$, \n",
    "$H^{0}_1 : \\beta_0 \\neq 0$\n",
    "\n",
    "$H^{1}_0 : \\beta_1 = 0$, \n",
    "$H^{1}_1 : \\beta_1 \\neq 0$\n",
    "\n",
    "$H^{2}_0 : \\beta_2 = 0$, \n",
    "$H^{2}_1 : \\beta_2 \\neq 0$\n",
    "\n",
    "$H^{3}_0 : \\beta_3 = 0$, \n",
    "$H^{3}_1 : \\beta_3 \\neq 0$\n",
    "\n",
    "De acuerdo a los p-values podemos observar que tanto el intercepto como la televisión y el radio tienen coeficientes diferentes de cero, por lo tanto se rechaza la $H_0$ por la $H_1$, es decir, estas variables sí tienen una influencia en las ventas, por el contrario, el periodico tiene un p-value > 0.05 por lo que se acepta la $H_0$, lo que significa que el periodico no influye en las ventas.\n",
    " \n",
    "Vemos que por sí solo, es decir, si no se hiciera un gato de publicidad en televisión o en radio, aun así se harían ventas, también podemos concluir que una unidad monetaria adicional a la publicidad en radio tiene un mayor impacto que una en televisión, lo que significa que la radio influye más en las ventas que la televisión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Carefully explain the differences between the KNN classifier and KNN regression methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El clasificador KNN es un método para clasificar, dado un entero positivo K y una observación de prueba $x_0$, se identifica los K puntos que están más cerca de $x_0$, representados por $N_0$, luego estima la probabilidad condicional $P(Y = j | X = x_{0})$ cuyos valores de respuesta son iguales a j. Por su parte el método de regresión KNN también toma un punto de predicción $x_{0}$, también identifica las K observaciones más cercanas a K de $x_{0}$ ($N_{0}$), la diferencia es que este método estima $f(x_{0})$ usando el promedio de todas las respuestas de entrenamiento en $N_{0}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Suppose we have a data set with five predictors: \n",
    "\n",
    "$X_1$ = GPA; \n",
    "\n",
    "$X_2$ = IQ; \n",
    "\n",
    "$X_3$ = Gender (1 for Female and 0 forMale); \n",
    "\n",
    "$X_4$ = Interaction between GPA and IQ, and; \n",
    "\n",
    "$X_5$ = Interaction between GPA and Gender. \n",
    "\n",
    "The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get \n",
    "\n",
    "$\\hat{β_0} = 50$; \n",
    "\n",
    "$\\hat{β_1} = 20$; \n",
    "\n",
    "$\\hat{β_2} = 0.07$; \n",
    "\n",
    "$\\hat{β_3} = 35$; \n",
    "\n",
    "$\\hat{β_4} = 0.01$; \n",
    "\n",
    "$\\hat{β_5} = −10$.\n",
    "\n",
    "a) Which answer is correct, and why?\n",
    "\n",
    "i. For a fixed value of IQ and GPA, males earn more on average than females.\n",
    "\n",
    "ii. For a fixed value of IQ and GPA, females earn more on average than males.\n",
    "\n",
    "iii. For a fixed value of IQ and GPA, males earn more on average than females provided that the GPA is high enough.\n",
    "\n",
    "iv. For a fixed value of IQ and GPA, females earn more on average than males provided that the GPA is high enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos como se ve la ecuación:\n",
    "\n",
    "$$ \\hat{y} = 50 + 20 x_{\\text{GPA}} + 0.07 x_{\\text{IQ}} + 35 x_{\\text{GENDER}} + 0.01 x_{\\text{GPA} \\times \\text{IQ}} - 10 x_{\\text{GPA} \\times \\text{GENDER}}$$\n",
    " \n",
    "Vemos que de todos los parámetros estimados existe uno que tiene una influencia negativa en el salario después de la graduación, la interacción entre el GPA y el género. En el caso de los hombres, este parámetro no afecta ya que se multiplica por cero dada la codificación, sin embargo, en el caso de las mujeres vemos que sí influye negativamente. Por lo tanto el salario promedio de los hombres será mayor siempre que el GPA sea lo suficientemente alto, por lo tanto la respuesta iii es la correcta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Predict the salary of a female with IQ of 110 and a GPA of 4.0.\n",
    "\n",
    "$\\hat{y} = 50 + 20 \\times 4 + 0.07 \\times 110 + 35 \\times 1 + 0.01 (4 \\times 110) - 10 (4 \\times 1)$\n",
    "\n",
    "$\\hat{y} = 50 + 80 +  7.7 + 35 + 4.4 - 40 = 137.1$\n",
    "\n",
    "Por lo tanto el salario inicial de una mujer recién egresada con un IQ de 110 y un GPA de 4.0 es de 137.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) True or false: Since the coefficient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer.\n",
    "\n",
    "Sí bien es cierto que el coeficiente de $x_{\\text{GPA} \\times \\text{IQ}}$ es de 0.01, la evidencia de un efecto de interacción se debería de evaluar con el p-value y no con la magnitud del coeficiente, por lo tanto es Falso."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. I collect a set of data ($n$ = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. $Y = β_0 + β_1X + β_2X^2 + β_3X^3 + e$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Suppose that the true relationship between $X$ and $Y$ is linear, i.e. $Y = β_0 + β_1X + e$. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    "Dado que la relación real entre $X$ y $Y$ es lineal, es probable que la regresión lineal, usando los datos de entrenamiento, se ajuste mejor y por lo tanto el RSS sea menor pues el modelo lineal se acercará más a la relación real que la regresión cúbica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Answer (a) using test rather than training RSS.\n",
    "\n",
    "De forma similar, aún cuando usemos los datos de prueba, dado que la relación real entre $X$ y $Y$ es lineal, es probable que la regresión lineal se ajuste mejor que la regresión cúbica y por lo tanto el RSS sea menor para la regresión lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.\n",
    "\n",
    "Si la relación real no es lineal, entonces, es probable que la regresión cúbica se ajuste mejor a los datos reales, utilizando los datos de entrenamiento, por lo que su RSS sería el más bajo y esto ocurre porque el modelo cúbico es más flexible al tener un mayor número de parámetros. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Answer (c) using test rather than training RSS.\n",
    "\n",
    "De forma similar, aun cuando usemos los datos de prueba, si la relación real no es lineal, entonces es probable que la regresión cúbica se ajuste mejor a los datos reales, por lo que su RSS sería el más bajo y esto ocurre porque el modelo cúbico es más flexible al tener un mayor número de parámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Consider the fitted values that result from performing linear regression without an intercept. In this setting, the i-th fitted value takes the form\n",
    "\n",
    "$$ \\hat{y_i} = x_i \\hat{\\beta}, $$\n",
    "\n",
    "where\n",
    "\n",
    "$$ \\hat{\\beta} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i'=1}^{n}x_{i'}^{2}}.  $$\n",
    "\n",
    "Show that we can write\n",
    "\n",
    "$$ \\hat{y_i} = \\sum_{i'=1}^{n} a_{i'}y_{i'}$$\n",
    "\n",
    "What is $a_{i'}$?\n",
    "\n",
    "Note: We interpret this result by saying that the fitted values from linear regression are linear combinations of the response values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero sustituimos $\\hat{\\beta}$ en la regresión lineal y para facilitar el entendimiento, sustituimos $i'$ por $j$:\n",
    "\n",
    "$ \\hat{y_i} = x_i \\hat{\\beta} = x_i  \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{j=1}^{n}x_{j}^{2}} $\n",
    "\n",
    "$ \\hat{y_i} = \\frac{x_i}{\\sum_{j = 1}^{n}x_{j}^{2}} \\sum_{i=1}^{n} x_i y_i$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$ c_i = \\frac{x_i}{\\sum_{j = 1}^{n}x_{j}^{2}}$\n",
    "\n",
    "Esto porque $ c_i$ no varia con el valor de los $j$. Entonces:\n",
    "\n",
    "$ \\hat{y_i} = c_i \\sum_{i=1}^{n} x_j y_j = \\sum_{i=1}^{n} a_j y_j  = \\sum_{i=1}^{n} a_{i'} y_{i'}$\n",
    "\n",
    "Por lo tanto $a_{i'} = c_ix_j = \\frac{x_i x_{i'}}{\\sum_{j = 1}^{n}x_{j}^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Using (3.4), argue that in the case of simple linear regression, the least squares line always passes through the point ($\\overline{x}$, $\\overline{y}$).\n",
    "\n",
    "![img2](2.png)\n",
    "\n",
    "Dónde:\n",
    "\n",
    "$\\overline{y} = \\frac{1}{n}\\sum_{i = 1}^{n} y_i$;\n",
    "\n",
    "$\\overline{x} = \\frac{1}{n}\\sum_{i = 1}^{n} x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la regresión de mínimos cuadrados:\n",
    " \n",
    "$ \\hat{y_i} = \\hat{\\beta_0} + \\hat{\\beta_1} x_i = \\overline{y} - \\hat{\\beta_1} \\overline{x} + \\hat{\\beta_1} x_i$\n",
    " \n",
    "Entonces:\n",
    " \n",
    "$ \\hat{y_i} = \\overline{y} - \\hat{\\beta_1} \\overline{x} + \\hat{\\beta_1} x_i$\n",
    " \n",
    "$ \\hat{y_i} - \\overline{y} =  \\hat{\\beta_1} (\\overline{x} + x_i)$\n",
    " \n",
    "Sí $x_i = \\overline{x}$ entonces:\n",
    " \n",
    "$ \\hat{y_i} - \\overline{y} = 0$\n",
    " \n",
    "Por lo tanto\n",
    " \n",
    "$ \\hat{y_i} = \\overline{y}$\n",
    " \n",
    "Entonces, vemos que la recta de mínimos cuadrados pasa por los puntos ($ \\overline{x}, \\overline{y}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. It is claimed in the text that in the case of simple linear regression of $Y$ onto $X$, the $R^2$ statistic (3.17) is equal to the square of the correlation between $X$ and $Y$ (3.18). Prove that this is the case. For simplicity, you may assume that $\\overline{x} = \\overline{y} = 0$.\n",
    "\n",
    "![img3](3.png)\n",
    "\n",
    "![img4](4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos:\n",
    "\n",
    "- $\\hat{\\beta_{0}} = 0$\n",
    "\n",
    "- $\\hat{\\beta_{1}} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_{i}^{2}}$\n",
    "\n",
    "- $R^{2} = \\frac{TSS - RSS}{TSS}$\n",
    "\n",
    "- $\\hat{y_{i}} = \\hat{\\beta_{1}} x_i$\n",
    "\n",
    "- $RSS = \\sum_{i = 1}^{n} (y_{i} - \\hat{y_i})^2$\n",
    "\n",
    "- $TSS = \\sum_{i=1}^{n} y_{i}^{2}$\n",
    "\n",
    "- $\\hat{y_i} = \\hat{\\beta_1} x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sustituimos: $\\hat{y_i}$\n",
    "\n",
    "$RSS = \\sum_{i = 1}^{n} (y_{i} - \\hat{\\beta_1} x_i)^2$\n",
    "\n",
    "$RSS = \\sum_{i = 1}^{n} (y_{i}^2 - 2\\hat{\\beta_1} x_i + \\hat{\\beta_1^2} x_i^2)^2$\n",
    "\n",
    "$RSS = \\sum_{i = 1}^{n}y_{i}^2 - \\hat{\\beta_1} (\\hat{\\beta_1} \\sum_{i = 1}^n x_i^2 - 2 \\sum_{i = 1}^nx_iy_i) $\n",
    "\n",
    "Sustituimos $\\hat{\\beta_1} = \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_{i}^{2}}$\n",
    "\n",
    "$ RSS = \\sum_{i = 1}^{n}y_{i}^2 - \\hat{\\beta_1} (\\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_{i}^{2}} \\sum_{i = 1}^n x_i^2 - 2 \\sum_{i = 1}^nx_iy_i) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ RSS = \\sum_{i = 1}^{n}y_{i}^2 - \\hat{\\beta_1} (\\sum_{i=1}^{n} x_i y_i - 2 \\sum_{i = 1}^nx_iy_i) $\n",
    "\n",
    "$ RSS = \\sum_{i = 1}^{n}y_{i}^2 - \\hat{\\beta_1} ( \\sum_{i = 1}^nx_iy_i) $\n",
    "\n",
    "\n",
    "$ RSS = \\sum_{i = 1}^{n}y_{i}^2 - \\frac{\\sum_{i=1}^{n} x_i y_i}{\\sum_{i=1}^{n} x_{i}^{2}} ( \\sum_{i = 1}^nx_iy_i) $\n",
    "\n",
    "$ RSS = \\sum_{i = 1}^{n}y_{i}^2 - \\frac{\\sum_{i=1}^{n} (x_i y_i)^2}{\\sum_{i=1}^{n} x_{i}^{2}} $\n",
    "\n",
    "$ RSS = \\frac{\\sum_{i = 1}^{n}y_{i}^2\\sum_{i = 1}^{n}x_{i}^{2} - \\sum_{i=1}^{n} (x_i y_i)^2}{\\sum_{i=1}^{n} x_{i}^{2}} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sustituimos en $R^2$ los valores de TSS y RSS:\n",
    "\n",
    "$R^{2} = \\frac{\\sum_{i=1}^{n} y_{i}^{2} - \\frac{\\sum_{i = 1}^{n}y_{i}^2\\sum_{i=1}^{n}x_{i}^{2} - \\sum_{i=1}^{n} (x_i y_i)^2}{\\sum_{i=1}^{n} x_{i}^{2}}}{\\sum_{i=1}^{n} y_{i}^{2}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^{2} = \\frac{\\sum_{i=1}^{n} y_{i}^{2} {\\sum_{i=1}^{n} x_{i}^{2}} - \\sum_{i = 1}^{n}y_{i}^2\\sum_{i=1}^{n}x_{i}^{2} + \\sum_{i=1}^{n} (x_i y_i)^2}{\\sum_{i=1}^{n} y_{i}^{2} {\\sum_{i=1}^{n} x_{i}^{2}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$R^{2} = \\frac{\\sum_{i=1}^{n} (x_i y_i)^2}{\\sum_{i=1}^{n} y_{i}^{2} {\\sum_{i=1}^{n} x_{i}^{2}}}$\n",
    "\n",
    "Y entonces: \n",
    "\n",
    "$Cor(x, y)^2 = \\frac{\\sum_{i=1}^{n} (x_i y_i)^2}{\\sum_{i=1}^{n} y_{i}^{2} {\\sum_{i=1}^{n} x_{i}^{2}}} = R^{2}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82f116a381a6bdd5c9d11b05964be2f9ca9f222cb54ba4a3fb82802bfa236998"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
