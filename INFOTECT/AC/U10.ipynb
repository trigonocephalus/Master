{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 222,
=======
   "execution_count": 44,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 223,
=======
   "execution_count": 45,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 224,
=======
   "execution_count": 46,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10,\n",
    "            shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 225,
=======
   "execution_count": 47,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "# for tr, vs in kf.split(X):\n",
    "#     print(tr)\n",
    "#     print(\"============\")\n",
    "#     print(vs)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 226,
=======
   "execution_count": 7,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos los datos en este arreglo\n",
    "hy = np.empty_like(y)\n",
    "\n",
    "# Dividimos en datos de entrenamiento y validacion\n",
    "for tr, vs in kf.split(X):\n",
    "\n",
    "    # Entrenamos el modelo\n",
    "    m = LinearSVC().fit(X[tr], y[tr])\n",
    "    \n",
    "    # predecimos con los datos de validación\n",
    "    hy[vs] = m.predict(X[vs])"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 227,
=======
   "execution_count": 8,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "0.9488970819786806"
      ]
     },
     "execution_count": 227,
=======
       "0.9549083785164385"
      ]
     },
     "execution_count": 8,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ya estimado el hy podemos medir el score\n",
    "lsvc_perf = f1_score(y,\n",
    "                     hy, \n",
    "                    average = 'macro')\n",
    "lsvc_perf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La idea es dividir el conjunto de entrenamiento en dos y solamente entrenariamos con la mitad, la otra mitad se desperdicia, y entrenando solo con la mitad se entrenara varias veces y vamos a predecir."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 228,
=======
   "execution_count": 9,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "# hy para guardar los datos\n",
    "hy = np.empty_like(y)\n",
    "\n",
    "# Usamos el mismo paso de Kfold\n",
    "for tr, vs in kf.split(X):\n",
    "\n",
    "\n",
    "\n",
    "    # Vamos a guardar varios modelos\n",
    "    models = []\n",
    "\n",
    "    for _ in range(2):\n",
    "\n",
    "        # Queremos que el conjunto de entrenamiento representado por esos indices se divida en dos.\n",
    "        tr1, tr2 = train_test_split(tr, test_size = 0.5, shuffle = True)\n",
    "\n",
    "        # Entrenamos el modelo    \n",
    "        models.append(LinearSVC().fit(X[tr1], y[tr1]))\n",
    "    \n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas queremos predecir algo, en este caso la función de decision"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 229,
=======
   "execution_count": 10,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "[array([[ -4.52512067,  -6.30528015,   3.17808847, ...,  -1.87452706,\n",
       "          -5.99978196, -13.87283432],\n",
       "        [ -2.78361605,  -2.99962673,  -5.34668638, ...,  -2.47969511,\n",
       "           0.1582429 ,  -8.85912341],\n",
       "        [ -3.44275125,  -2.63252628,  -1.20454676, ...,  -5.50650528,\n",
       "          -8.89202403,  -0.13648195],\n",
       "        ...,\n",
       "        [ -5.32667284,   5.37940141,  -3.52889899, ...,  -3.8689471 ,\n",
       "          -2.69698001, -17.13935684],\n",
       "        [ -4.00375742,  -2.08661971,  -4.15922224, ...,  -5.33232426,\n",
       "          -1.57605559, -21.72345483],\n",
       "        [ -4.32293902, -11.96444263,  -3.33036513, ...,  -6.08993937,\n",
       "           0.6101741 ,  -4.67219149]]),\n",
       " array([[ -5.21545418,  -2.74472788,   3.54468466, ...,  -3.38732653,\n",
       "          -5.20966728, -12.27945069],\n",
       "        [ -2.97721413,   2.19513692,  -7.52423507, ...,  -2.39701563,\n",
       "          -3.09262368, -16.24255578],\n",
       "        [ -3.83704702,  -0.70934341,  -1.62900401, ...,  -7.71693552,\n",
       "          -6.11236157,  -1.2625697 ],\n",
       "        ...,\n",
       "        [ -5.48693858,   5.12146404,  -4.68765436, ...,  -5.57210056,\n",
       "          -2.0744418 , -15.29786293],\n",
       "        [ -3.41183766,  -1.26053295,  -4.92597012, ...,  -6.60327742,\n",
       "          -1.78107987, -24.21276047],\n",
       "        [ -4.82918721,  -7.74766312,  -4.85311639, ...,  -7.42816971,\n",
       "           1.68146444,  -6.54504409]])]"
      ]
     },
     "execution_count": 229,
=======
       "[array([[ -2.12445068,  -5.93718672,  -7.74544556, ...,  -4.3562226 ,\n",
       "          -4.30754313, -13.21845487],\n",
       "        [ -4.17089044,  -8.81813547,  -6.44839305, ...,   1.45127921,\n",
       "          -8.28757488, -11.38042965],\n",
       "        [  2.07860833,  -7.23271644,  -3.2924245 , ...,  -4.52039032,\n",
       "          -4.82231668,  -7.07341577],\n",
       "        ...,\n",
       "        [ -4.17203622,   1.31162681,  -4.48875473, ...,  -4.51415254,\n",
       "          -0.26118532, -15.57601527],\n",
       "        [ -4.72193489, -10.71101545,  -4.73121478, ...,   2.40249412,\n",
       "          -9.77514184, -12.73014012],\n",
       "        [ -2.74316636,  -5.93792165,  -2.21921854, ...,  -4.90490675,\n",
       "          -4.42744896,  -0.96720084]]),\n",
       " array([[ -1.16639683,  -5.15471703,  -6.48087045, ...,  -3.30088257,\n",
       "          -3.31340822, -15.02169741],\n",
       "        [ -4.32008327, -10.0056712 ,  -5.02837755, ...,   2.3733056 ,\n",
       "          -8.08660989,  -8.70002946],\n",
       "        [  1.61383095,  -8.98331207,  -2.9170566 , ...,  -3.21983017,\n",
       "          -7.69095318,  -6.77777557],\n",
       "        ...,\n",
       "        [ -4.59370463,   2.65187421,  -3.56774377, ...,  -5.36473274,\n",
       "          -0.75992052, -14.9101886 ],\n",
       "        [ -4.45837955,  -9.95353184,  -3.97277942, ...,   2.60422508,\n",
       "          -8.74964173, -10.71152137],\n",
       "        [ -2.49223678,  -8.48003509,  -2.99197752, ...,  -6.60165211,\n",
       "          -5.6972681 ,   1.42421012]])]"
      ]
     },
     "execution_count": 10,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m.decision_function(X[vs]) for m in models]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 230,
=======
   "execution_count": 11,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 180, 10)"
      ]
     },
<<<<<<< HEAD
     "execution_count": 230,
=======
     "execution_count": 11,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([m.decision_function(X[vs]) for m in models]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que acabamos de hacer es preguntarle a cada modelo por la función de desición, podemos tomar la media de la función de desicion y con esa media utilizar."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 231,
=======
   "execution_count": 12,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([ -4.87028742,  -4.52500402,   3.36138656,  -7.79453951,\n",
       "        -5.81042726,  -5.50223757,  -4.1456292 ,  -2.63092679,\n",
       "        -5.60472462, -13.07614251])"
      ]
     },
     "execution_count": 231,
=======
       "array([ -1.64542376,  -5.54595187,  -7.113158  , -19.85286328,\n",
       "         2.08607398, -11.54495512,  -5.5441065 ,  -3.82855259,\n",
       "        -3.81047568, -14.12007614])"
      ]
     },
     "execution_count": 12,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([m.decision_function(X[vs]) for m in models]).mean(axis = 0)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui indica a que clase pertence"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 232,
=======
   "execution_count": 13,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "array([2, 4, 9, 5, 2, 6, 1, 2, 4, 8, 1, 8, 7, 5, 4, 0, 5, 8, 1, 7, 7, 1,\n",
       "       4, 2, 8, 5, 6, 3, 5, 1, 5, 9, 7, 0, 2, 2, 6, 6, 1, 9, 3, 3, 8, 4,\n",
       "       5, 9, 0, 7, 1, 0, 2, 2, 8, 1, 4, 8, 0, 7, 4, 6, 1, 9, 6, 4, 4, 7,\n",
       "       8, 3, 4, 0, 1, 6, 6, 8, 1, 6, 1, 8, 4, 8, 1, 4, 3, 0, 2, 8, 5, 7,\n",
       "       2, 6, 6, 7, 1, 2, 2, 3, 5, 6, 3, 0, 7, 5, 5, 2, 4, 9, 2, 4, 9, 9,\n",
       "       7, 3, 4, 8, 0, 0, 7, 8, 2, 7, 7, 0, 5, 1, 4, 6, 4, 7, 8, 1, 2, 0,\n",
       "       7, 5, 8, 0, 7, 3, 1, 2, 8, 8, 2, 6, 1, 8, 5, 4, 0, 1, 0, 0, 1, 6,\n",
       "       9, 6, 2, 2, 5, 7, 3, 7, 2, 0, 9, 5, 4, 1, 8, 3, 7, 1, 6, 5, 0, 4,\n",
       "       3, 1, 6, 8], dtype=int64)"
      ]
     },
     "execution_count": 232,
=======
       "array([4, 7, 0, 8, 0, 6, 0, 3, 5, 0, 3, 3, 6, 0, 8, 1, 0, 0, 3, 6, 1, 3,\n",
       "       1, 1, 8, 7, 2, 1, 9, 6, 1, 8, 2, 6, 9, 8, 9, 0, 7, 1, 1, 4, 7, 4,\n",
       "       9, 4, 5, 1, 6, 7, 3, 2, 0, 7, 4, 1, 4, 4, 7, 1, 2, 9, 8, 3, 6, 2,\n",
       "       0, 4, 9, 3, 4, 5, 0, 5, 1, 5, 0, 1, 4, 8, 8, 5, 8, 7, 5, 9, 6, 4,\n",
       "       5, 4, 6, 7, 3, 6, 2, 2, 1, 6, 7, 5, 4, 2, 7, 0, 5, 8, 6, 3, 1, 3,\n",
       "       3, 2, 3, 1, 9, 9, 0, 2, 4, 9, 0, 6, 9, 8, 1, 1, 6, 0, 7, 0, 4, 2,\n",
       "       3, 4, 1, 7, 8, 3, 5, 0, 3, 3, 1, 1, 4, 0, 4, 8, 1, 3, 9, 2, 3, 1,\n",
       "       3, 7, 8, 6, 0, 7, 0, 1, 1, 9, 5, 1, 4, 3, 8, 9, 1, 6, 9, 7, 3, 1,\n",
       "       6, 1, 7, 9], dtype=int64)"
      ]
     },
     "execution_count": 13,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([m.decision_function(X[vs]) for m in models]).mean(axis = 0).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esto es nuestra predicción:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 233,
=======
   "execution_count": 14,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = np.empty_like(y)\n",
    "\n",
    "for tr, vs in kf.split(X):\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for _ in range(2):\n",
    "\n",
    "        tr1, tr2 = train_test_split(tr, test_size = 0.5, shuffle=True)\n",
    "        \n",
    "        models.append(LinearSVC().fit(X[tr1], y[tr1]))\n",
    "\n",
    "    hy[vs] = np.array([m.decision_function(X[vs]) for m in models]).mean(axis = 0).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 234,
=======
   "execution_count": 15,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(0.9488970819786806, 0.9448802969924662)"
      ]
     },
     "execution_count": 234,
=======
       "(0.9549083785164385, 0.9413528000472015)"
      ]
     },
     "execution_count": 15,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_perf, f1_score(y, hy, average='macro')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 235,
=======
   "execution_count": 16,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = np.empty_like(y)\n",
    "\n",
    "for tr, vs in kf.split(X):\n",
    "    models = []\n",
    "    for _ in range(4):\n",
    "        tr1, tr2 = train_test_split(tr, test_size = 0.5, shuffle=True)\n",
    "        models.append(LinearSVC().fit(X[tr1], y[tr1]))\n",
    "\n",
    "    hy[vs] = np.array([m.decision_function(X[vs]) for m in models]).mean(axis = 0).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 236,
=======
   "execution_count": 17,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(0.9488970819786806, 0.9504063071225038)"
      ]
     },
     "execution_count": 236,
=======
       "(0.9549083785164385, 0.9542966959420223)"
      ]
     },
     "execution_count": 17,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_perf, f1_score(y, hy, average='macro')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 239,
=======
   "execution_count": 18,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [],
   "source": [
    "hy = np.empty_like(y)\n",
    "\n",
    "for tr, vs in kf.split(X):\n",
    "    models = []\n",
    "    for _ in range(10):\n",
    "        tr1, tr2 = train_test_split(tr, test_size = 0.5, shuffle=True)\n",
    "        models.append(LinearSVC().fit(X[tr1], y[tr1]))\n",
    "\n",
    "    hy[vs] = np.array([m.decision_function(X[vs]) for m in models]).mean(axis = 0).argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 240,
=======
   "execution_count": 19,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "(0.9488970819786806, 0.9578552980917902)"
      ]
     },
     "execution_count": 240,
=======
       "(0.9549083785164385, 0.9516447268969651)"
      ]
     },
     "execution_count": 19,
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsvc_perf, f1_score(y, hy, average='macro')"
   ]
  },
  {
<<<<<<< HEAD
=======
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos un arreglo de tamaño y\n",
    "hy = np.empty_like(y)\n",
    "\n",
    "# Dividimos en datos de entrenamiento y validacion\n",
    "for tr, vs in kf.split(X):\n",
    "\n",
    "    # Entrenamos el modelol\n",
    "    m = GaussianNB().fit(X[tr], y[tr])\n",
    "\n",
    "    # Validamos el modelo\n",
    "    hy[vs] = m.predict(X[vs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8417341327289918"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Revisamos el resultado\n",
    "f1_score(y, hy, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(base_cl, X, y):\n",
    "\n",
    "    # un arreglo de tamaño y\n",
    "    df = np.empty((X.shape[0], np.unique(y).shape[0]))\n",
    "\n",
    "    # Kfold\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    # Dividimos en datos de entrenamiento y validacion\n",
    "    for tr, vs in kf.split(X):\n",
    "\n",
    "        # Se entrena con tr\n",
    "        m = base_cl().fit(X[tr], y[tr])\n",
    "\n",
    "        # Se valida con vs\n",
    "        df[vs] = m.predict_proba(X[vs])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr, vs in kf.split(X):\n",
    "\n",
    "    m1 = GaussianNB().fit(X[tr], y[tr])\n",
    "\n",
    "    st = RandomForestClassifier().fit(train(GaussianNB, X[tr], y[tr]), y[tr])\n",
    "\n",
    "    hy[vs] = st.predict(m1.predict_proba(X[vs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8765021968795246"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, hy, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(base_cl, X, y):\n",
    "\n",
    "    df = np.empty((X.shape[0], np.unique(y).shape[0]))\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "    for tr, vs in kf.split(X):\n",
    "\n",
    "        m = base_cl().fit(X[tr], y[tr])\n",
    "        try:\n",
    "            df[vs] = m.predict_proba(X[vs])\n",
    "\n",
    "        except AttributeError:\n",
    "            df[vs] = m.decision_function(X[vs])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tr, vs in kf.split(X):\n",
    "\n",
    "    m1 = GaussianNB().fit(X[tr], y[tr])\n",
    "\n",
    "    m2 = LinearSVC().fit(X[tr], y[tr])\n",
    "\n",
    "    _ = np.concatenate((train(GaussianNB, X[tr], y[tr]), train(LinearSVC, X[tr], y[tr])), axis = 1)\n",
    "\n",
    "    st = RandomForestClassifier().fit(_, y[tr])\n",
    "\n",
    "    _ = np.concatenate((m1.predict_proba(X[vs]), m2.decision_function(X[vs])), axis = 1)\n",
    "\n",
    "    hy[vs] = st.predict(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638211736052652"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, hy, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hy_svc = np.empty_like(y)\n",
    "hy_nb = np.empty_like(y)\n",
    "for tr, vs in kf.split(X):\n",
    "\n",
    "    m1 = GaussianNB().fit(X[tr], y[tr])\n",
    "\n",
    "    hy_nb[vs] = m1.predict(X[vs])\n",
    "\n",
    "    m2 = LinearSVC().fit(X[tr], y[tr])\n",
    "\n",
    "    hy_svc[vs] = m2.predict(X[vs])\n",
    "\n",
    "    _ = np.concatenate((train(GaussianNB, X[tr], y[tr]), train(LinearSVC, X[tr], y[tr])), axis = 1)\n",
    "\n",
    "    st = RandomForestClassifier().fit(_, y[tr])\n",
    "\n",
    "    _ = np.concatenate((m1.predict_proba(X[vs]), m2.decision_function(X[vs])), axis = 1)\n",
    "\n",
    "    hy[vs] = st.predict(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9418200013521867"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, hy_svc, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8397375068311727"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y, hy_nb, average='macro')"
   ]
  },
  {
>>>>>>> 83a00d0d987b5693acde250847cc17faeb69e9de
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "82f116a381a6bdd5c9d11b05964be2f9ca9f222cb54ba4a3fb82802bfa236998"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
